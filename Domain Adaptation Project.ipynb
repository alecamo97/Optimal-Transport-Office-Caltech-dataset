{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Optimal Transport Project - Advanced Machine Learning**\n",
    "\n",
    "The objective of this project is to implement two different domain adaptation methods and to test them on the real-world computer vision ***Office/Caltech data set.*** The two methods are: ***subspace alignment*** and ***Entropic regularized optimal transport.***\n",
    "\n",
    "`subspace alignment:` aims to project the labeled source and unlabeled target samples $S$ and $T$ in two subspaces spanned by their principal components so that the divergence between the two domains is minimized.\n",
    "\n",
    "`Entropic regularized optimal transport:` It uses the *Sinkhorn-Knopp algorithm* to solve the entropic regularized OT problem between two empirical distributions of data matrices $S$ and $T$. This algorithm iteratively balances row and column sums in the transport matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import cdist\n",
    "from numpy.linalg import norm\n",
    "import ot\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load Data**\n",
    "\n",
    "For this project on two domains of the *Office/Caltech data set*: Webcam $(W)$ and DSLR $(D)$; they contain $295$ and $157$ observations respectively. The images have two data representations.\n",
    "\n",
    "`CaffeNet4096` that contains 4096 numerical features representing the images and `Surf`has 800 features. For this project it was used the *Surf* dataset due to less computational cost and similar performance to the *CaffeNet4096*.\n",
    "\n",
    "We then extract data and labels for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'fts', 'labels'])\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'fts', 'labels'])\n",
      "Dimensions webcam dataset: \n",
      " (295, 800)\n",
      "Number of classes:  10\n",
      "Dimensions dslr dataset \n",
      " (157, 800)\n",
      "Number of classes:  10\n"
     ]
    }
   ],
   "source": [
    "surf_dir = 'Surf/'\n",
    "\n",
    "data_webcam = loadmat(os.path.join(surf_dir, 'webcam.mat'))\n",
    "X_webcam = data_webcam['fts']\n",
    "y_webcam = data_webcam['labels'].flatten()\n",
    "\n",
    "data_dslr = loadmat(os.path.join(surf_dir, 'dslr.mat'))\n",
    "X_dslr = data_dslr['fts']\n",
    "y_dslr = data_dslr['labels'].flatten()\n",
    "\n",
    "print(data_webcam.keys())\n",
    "print(data_dslr.keys())\n",
    "\n",
    "num_classes_webcam = len(np.unique(y_webcam))\n",
    "num_classes_dslr = len(np.unique(y_dslr))\n",
    "\n",
    "print(\"Dimensions webcam dataset: \\n\", X_webcam.shape)\n",
    "print(\"Number of classes: \", num_classes_webcam)\n",
    "print(\"Dimensions dslr dataset \\n\", X_dslr.shape,)\n",
    "print(\"Number of classes: \", num_classes_dslr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'labels', 'fts'])\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'labels', 'fts'])\n",
      "Dimensions webcam dataset: \n",
      " (295, 4096)\n",
      "Number of classes:  10\n",
      "Dimensions dslr dataset \n",
      " (157, 4096)\n",
      "Number of classes:  10\n"
     ]
    }
   ],
   "source": [
    "surf_dir = 'CaffeNet4096/'\n",
    "\n",
    "data_webcam = loadmat(os.path.join(surf_dir, 'webcam.mat'))\n",
    "X_webcam = data_webcam['fts']\n",
    "y_webcam = data_webcam['labels'].flatten()\n",
    "\n",
    "data_dslr = loadmat(os.path.join(surf_dir, 'dslr.mat'))\n",
    "X_dslr = data_dslr['fts']\n",
    "y_dslr = data_dslr['labels'].flatten()\n",
    "\n",
    "print(data_webcam.keys())\n",
    "print(data_dslr.keys())\n",
    "\n",
    "num_classes_webcam = len(np.unique(y_webcam))\n",
    "num_classes_dslr = len(np.unique(y_dslr))\n",
    "\n",
    "print(\"Dimensions webcam dataset: \\n\", X_webcam.shape)\n",
    "print(\"Number of classes: \", num_classes_webcam)\n",
    "print(\"Dimensions dslr dataset \\n\", X_dslr.shape,)\n",
    "print(\"Number of classes: \", num_classes_dslr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Data normalization (features)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Z-score normalization \n",
    "X_webcam = scaler.fit_transform(X_webcam) \n",
    "X_dslr = scaler.fit_transform(X_dslr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **First Method: Subspace Alignment:**\n",
    "\n",
    "The procedure followed in this method takes as reference the paper\n",
    "\n",
    "The Subspace alignment method aims to project the labeled source and unlabeled target samples **S** ($n_s \\times D$ matrix) and **T** ($n_t \\times D$ matrix) into two subspaces spanned by their principal components, so that the divergence between the two domains is minimized.\n",
    "\n",
    "Let the source samples **S** and target samples **T** be defined as:\n",
    "\n",
    "$$\n",
    "S \\in \\mathbb{R}^{n_s \\times D}, \\quad T \\in \\mathbb{R}^{n_t \\times D}\n",
    "$$\n",
    "\n",
    "The methodology applied in this methos is mainly based on the approach outlined in Fernando et al.'s paper, *Unsupervised Visual Domain Adaptation Using Subspace Alignment*. The paper is available [here](https://openaccess.thecvf.com/content_iccv_2013/papers/Fernando_Unsupervised_Visual_Domain_2013_ICCV_paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Finding the optimal nuber of components $d^*$ for the source $X_s \\in \\mathbb{R}^{D \\times d}$ and target $X_t \\in \\mathbb{R}^{D \\times d}$**\n",
    "\n",
    "This part consists of two processes: First finding the maximum number of components $d_\\text{max}$ and then applying cross-validation to find the optimal number of components $d^*$.\n",
    "\n",
    "**Finding the maximum number of components $d_{\\text{max}}$**\n",
    "\n",
    "In this section, we need to find the principal components with the highest variance, which are denoted as $X_s \\in \\mathbb{R}^{D \\times d}$ for the source and $X_t \\in \\mathbb{R}^{D \\times d}$ for the target.\n",
    "\n",
    "The $d$ paramater was tunned following the process of the paper, where it stablishes through a theorem that we can deduce a bound on the deviation between two successive eigenvalues. We can make use of this bound as a cutting rule for automatically determining the size of the subspaces.\n",
    "\n",
    "The paper determines that given a confidence $\\delta > 0$ and a fixed deviation $\\gamma > 0$, we can select the maximum dimension $d_{\\text{max}}$ such that:\n",
    "\n",
    "$$\n",
    "\\left( \\lambda_{\\text{min}}^{d_{\\text{max}}} - \\lambda_{\\text{min}}^{d_{\\text{max}} + 1} \\right) \\geq \\left( 1 + \\sqrt{\\frac{\\ln 2 / \\delta}{2}} \\right) \\left( \\frac{16 d^{3/2} B}{\\gamma \\sqrt{n_{\\text{min}}}} \\right)\n",
    "$$\n",
    "\n",
    "For each $d \\in \\{ d \\mid 1, \\dots, d_{\\text{max}} \\}$, we then have the guarantee that as long as we select a subspace dimension $d$ such that $d \\leq d_{\\text{max}}$, the solution is stable and not over-fitting.\n",
    "\n",
    "The values of the parameters $\\gamma$, $\\delta$, and $n_{\\text{min}}$ were selected as follows:\n",
    "\n",
    "- $\\gamma = 10^5$: This is the same value used in the paper for adaptation from W to C. Although we are adapting from W to D, this value provided the best results.\n",
    "- $\\delta = 0.1$: This value represents a 90% confidence interval $(1- \\gamma)$ for detecting significant shifts in eigenvalue differences. It is also consistent with the value used in the paper.\n",
    "- $n_{\\text{min}}$: This is the minimum sample size of the two datasets, `X_webcam` and `X_dslr`, ensuring that the stability criterion applies to both domains.\n",
    "\n",
    "Different values were tested in this part, but the result of $d_{\\text{max}}$ didn't fluctuate too much. For that reason it was decided to select the same values used in the paper.\n",
    "\n",
    "**Cross validation to find the optimal number of dimensions $d^*$**\n",
    "\n",
    "For this part, we chose to follow the approach outlined in the paper, which involves applying *2-fold cross-validation* using a *1-NN* classifier to evaluate the accuracy of each method on the target domain over 30 random trials. This number of trials is greater than that used in the paper because, with fewer trials, the optimal dimension $d^*$ varied significantly between runs. Using 30 random trials provided more stable results.\n",
    "\n",
    "For each trial, we applied an unsupervised domain adaptation (DA) setting, where we randomly sampled labeled data in the source domain for training and used unlabeled data in the target domain as testing examples.\n",
    "\n",
    "Using the optimal dimensionality $d^*$, we apply PCA to both `X_webcam` and `X_dslr`, resulting in the final reduced datasets $X_s$ and $X_t$ with shapes $(n_s, d^*)$ and $(n_t, d^*)$, respectively. This dimensionality reduction prepares the datasets for further processing in the subspace alignment approach, minimizing domain divergence with an optimal choice of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum stable dimensionality (d_max): 156\n"
     ]
    }
   ],
   "source": [
    "def find_dmax(eigenvalues, gamma, beta, n_min, delta):  \n",
    "            \n",
    "    d_max = None\n",
    "\n",
    "    for d in range(len(eigenvalues) - 1):\n",
    "\n",
    "        # Deviation between consecutive eigenvalues\n",
    "        eigenvalue_diff = eigenvalues[d] - eigenvalues[d + 1]\n",
    "        \n",
    "        # Eq. 5 from the paper\n",
    "        rhs = (1 + np.sqrt(np.log(2 / delta) / 2)) * (((16 * (d)**(3/2)) * beta) / (gamma * np.sqrt(n_min)))\n",
    "        \n",
    "        # Condition to find d_max\n",
    "        if eigenvalue_diff >= rhs:\n",
    "            d_max = d + 1 \n",
    "            \n",
    "    return d_max if d_max else len(eigenvalues)  # Return d_max or max possible if not found\n",
    "\n",
    "# PCA on both the source (webcam) and target (dslr) datasets\n",
    "pca_webcam = PCA().fit(X_webcam)\n",
    "pca_dslr = PCA().fit(X_dslr)\n",
    "\n",
    "# Use the minimum number of components (in case the datasets have different dimensions)\n",
    "min_components = min(len(pca_webcam.singular_values_), len(pca_dslr.singular_values_))\n",
    "\n",
    "# Select only the first 'min_components' eigenvalues from both datasets\n",
    "eigenvalues_webcam = pca_webcam.singular_values_[:min_components]\n",
    "eigenvalues_dslr = pca_dslr.singular_values_[:min_components]\n",
    "\n",
    "# Now calculate the element-wise minimum\n",
    "eigenvalues = np.minimum(eigenvalues_webcam, eigenvalues_dslr)\n",
    "\n",
    "# Set values for gamma, beta, and n_min\n",
    "gamma = 1e5  # As mentioned in the paper\n",
    "beta = max(np.max(np.abs(X_webcam)), np.max(np.abs(X_dslr)))\n",
    "delta = 0.1  # Confidence value as per the paper\n",
    "n_min = min(X_webcam.shape[0], X_dslr.shape[0])\n",
    "\n",
    "# Calculate d_max\n",
    "d_max = find_dmax(eigenvalues, gamma, beta, n_min, delta)\n",
    "print(f'Maximum stable dimensionality (d_max): {d_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal dimensionality (best_d): 18 with cross-validated accuracy: 0.8488738738738739\n"
     ]
    }
   ],
   "source": [
    "# Function to perform 2-fold cross-validation to select optimal d\n",
    "def cross_validate_pca(Xs, y_webcam, d_max, n_trials=30):\n",
    "\n",
    "    best_d = None\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Loop over dimensionalities from 1 to d_max\n",
    "    for d in range(1, d_max + 1):\n",
    "\n",
    "        # Apply PCA with d components on the source dataset (Xs)\n",
    "        pca = PCA(n_components=d)\n",
    "        Xs_reduced = pca.fit_transform(Xs)\n",
    "\n",
    "        trial_accuracies = []\n",
    "\n",
    "        # Repeat the process for 30 random trials\n",
    "        for i in range(n_trials):\n",
    "\n",
    "            # Randomly sample a subset of the source data for training\n",
    "            X_train, X_test, y_train, y_test = train_test_split(Xs_reduced, y_webcam, test_size=0.5)            \n",
    "\n",
    "            # Train the KNN classifier on the labeled source domain\n",
    "            knn = KNeighborsClassifier(n_neighbors=1)\n",
    "            knn.fit(X_train, y_train)\n",
    "\n",
    "            # Make predictions on the source test set and calculate accuracy\n",
    "            y_pred = knn.predict(X_test)\n",
    "            trial_accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "            trial_accuracies.append(trial_accuracy)\n",
    "\n",
    "        # Calculate the average accuracy\n",
    "        avg_accuracy = np.mean(trial_accuracies)\n",
    "\n",
    "        # Update the best dimensionality if the current one has better accuracy\n",
    "        if avg_accuracy > best_accuracy:\n",
    "            best_accuracy = avg_accuracy\n",
    "            best_d = d\n",
    "\n",
    "    return best_d, best_accuracy\n",
    "\n",
    "best_d, best_accuracy = cross_validate_pca(X_webcam, y_webcam, d_max)\n",
    "print(f'Optimal dimensionality (best_d): {best_d} with cross-validated accuracy: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Source and target projected data in $\\mathbb{R}^d$**\n",
    "\n",
    "After determining the optimal number of dimensions $d^*$, we project the source data $S$ and target data $T$ into their respective subspaces $X_s$ and $X_t$. Following the procedure specified in the paper, this operation is performed as $\\hat{S} = S X_s$ and $\\hat{T} = T X_t$.\n",
    "\n",
    "\n",
    "**3. Optimal alignment Matrix $M$**\n",
    "\n",
    "Now, we we learn a linear transformation function that align the source subspace coordinate system to the target one using the *subspace alignment* aproach. The basis vectors are aligned by using a transformation matrix $M$ from $X_s$ to $X_t$ with the following formulation.\n",
    "\n",
    "$M = X_s^T X_t$\n",
    "\n",
    "After determining the optimal alignment matrix $M$, we compare the source data with the target data using a similarity function. The paper suggests a PSD approach that involves projecting the source data $\\hat{S}$ into the aligned target space $\\hat{T}$ using the transformation: $S_p = \\hat{S} M$.\n",
    "\n",
    "**4. Prediction of $\\hat{S}$ labels using *1-NN* algorithm**\n",
    "\n",
    "Finally, the projected source data in the target-aligned subspace $S_p$ is used to train a *1-NN* classifier with the original source labels `y_webcam`. The predictions are then compared with the actual labels of the target dataset, `y_dslr`, to calculate the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subspace_alignment(source_data, target_data, y_source, y_target, d):\n",
    "    \"\"\"\n",
    "    Perform subspace alignment on the source and target datasets.\n",
    "\n",
    "    Parameters:\n",
    "    source_data (array): Source data matrix.\n",
    "    target_data (array): Target data matrix.\n",
    "    y_source (array): Labels for the source data.\n",
    "    y_target (array): Labels for the target data.\n",
    "    d (int): Dimensionality to use for PCA.\n",
    "\n",
    "    Returns:\n",
    "    float: Accuracy of the classifier on the aligned target data.\n",
    "    \"\"\"\n",
    "\n",
    "    # PCA in both datasets with d\n",
    "    pca_source = PCA(n_components=d)\n",
    "    Xs = pca_source.fit_transform(source_data)\n",
    "\n",
    "    pca_target = PCA(n_components=d)\n",
    "    Xt = pca_target.fit_transform(target_data)\n",
    "\n",
    "    # Projection onto their PCA components\n",
    "    S_hat = source_data @ pca_source.components_.T  \n",
    "    T_hat = target_data @ pca_target.components_.T  \n",
    "\n",
    "    # Alignment matrix M \n",
    "    X_source = pca_source.components_.T  \n",
    "    X_target = pca_target.components_.T  \n",
    "    M = np.dot(X_source.T, X_target)  \n",
    "\n",
    "    # Align the projected source data to the target subspace\n",
    "    S_p = np.dot(S_hat, M) \n",
    "\n",
    "    # 1-NN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(S_p, y_source)\n",
    "    y_pred = knn.predict(Xt)\n",
    "    accuracy = accuracy_score(y_target, y_pred)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prediction of target labels using *1-NN***\n",
    "\n",
    "With the subspace alignment procedure implemented in a function that takes the source dataset $S$, target dataset $T$, and parameter $d$ as inputs and returns the accuracy of the *1-NN* classifier, we can now call this function to evaluate the accuracy on the aligned datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier after subspace alignment: 0.7898089171974523\n"
     ]
    }
   ],
   "source": [
    "accuracy = subspace_alignment(X_webcam, X_dslr, y_webcam, y_dslr, best_d)\n",
    "print(f'Accuracy of the classifier after subspace alignment: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prediction of target labels without projection**\n",
    "\n",
    "Similarly, we implemented a *1-NN* algorithm using the original source data (without any alignment) and calculated the accuracy on the target datasets, which were also not aligned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on target points without subspace alignment: 0.18471337579617833\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "pca_webcam_optimal = PCA(n_components=best_d)\n",
    "Xs = pca_webcam_optimal.fit_transform(X_webcam)  # Projected source data\n",
    "\n",
    "pca_dslr_optimal = PCA(n_components=best_d)\n",
    "Xt = pca_dslr_optimal.fit_transform(X_dslr)  \n",
    "\n",
    "# 1-NN classifier on the projected source data Xs\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(Xs, y_webcam)\n",
    "\n",
    "# Predict the labels of the projected target data Xt\n",
    "y_pred = knn.predict(Xt)\n",
    "\n",
    "# Calculate accuracy on the target data\n",
    "accuracy = accuracy_score(y_dslr, y_pred)\n",
    "print(f'Accuracy on target points without subspace alignment: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Entropic regularized optimal transport**\n",
    "\n",
    "Entropic regularized optimal transport is an approach to optimal transport (OT) that adds an entropy term to the classic OT problem to make it more computationally efficient and stable. The Sinkhorn algorithm is an iterative method to solve the entropic regularized OT problem by iteratively updating the transport matrix $M$ between two data matrices $S \\in \\mathbb{R}^{n_s \\times d}$ and $T \\in \\mathbb{R}^{n_t \\times d}$ through matrix scaling steps.\n",
    "\n",
    "**1. Uniform vectors *a* and *b*:** \n",
    "\n",
    "The vector $\\mathbf{a} \\in \\mathbb{R}^{n_s}$ and $\\mathbf{b} \\in \\mathbb{R}^{n_t}$ represents the uniform vectors for source and target dataset, where $n_s$ and $n_t$ are the number of observations of $S$ and $T$ respecitvely.\n",
    "\n",
    "For this project, the chosen value for the uniform vectors are:\n",
    "$\\mathbf{a} = \\left[\\frac{1}{n_s}, \\frac{1}{n_s}, \\ldots, \\frac{1}{n_s}\\right]^T \\in \\mathbb{R}^{n_s}$ and $\\mathbf{b} = \\left[\\frac{1}{n_t}, \\frac{1}{n_t}, \\ldots, \\frac{1}{n_t}\\right]^T \\in \\mathbb{R}^{n_t}$.\n",
    "\n",
    "This ensures that the vectors can be interpreted as probability distributions, with each observation being equally likely.\n",
    "\n",
    "**2. Cost Matriz calculation:**\n",
    "\n",
    "The cost matrix $M$ is defined as the pairwise Euclidean distance between the points in the source dataset $S$ and the target dataset $T$. Mathematically, this can be expressed as:\n",
    "\n",
    "$$M_{ij} = \\| S^i - T^j \\|^2$$\n",
    "\n",
    "where $S^i$ is the $i^\\text{th}$ observation from the source dataset, and $T^j$ is the $j^\\text{th}$ observation from the target dataset. The resulting matrix $M \\in \\mathbb{R}^{n_s \\times n_t}$ is then scaled for for subsequent computations.\n",
    "\n",
    "This operation was done ussing the command `scipy.spatial.distance.cdist`\n",
    "\n",
    "**3. Coupling matrix $\\gamma$:**\n",
    "\n",
    "The coupling matrix $\\gamma$ is a matrix that represents the optimal way to transport mass from a source distribution $a$ to a target distribution $b$. For this case, $\\gamma$ was calculated using the command `ot.sinkhorn(a, b, M, rege)`\n",
    "\n",
    "The parameter $rege$ is a regularization parameter that balances the trade-off between minimizing the transportation cost and maintaining the smoothness of the coupling matrix. \n",
    "\n",
    "In this case, a similar aproach to the one used to find the parameter $d^*$ was employed. A range of values for the entropic regularization parameter $rege = [0.001, 0.01, 0.1, 1]$ was established. The accuracy was evaluated through a *2-fold cross-validation* using a *1-NN* classifier over 20 different random trials.  It was noted that lower values of $rege$ corresponded to higher accuracy.\n",
    "\n",
    "Given that $S$ and $T$ datasets are not extensive, a small $rege$ value can be selected without negatively impacting the algorithm's efficiency.\n",
    "\n",
    "**4. Transport the points from $S$ to $T$ using the coupling matrix $\\gamma$:**\n",
    "\n",
    "After tuning the hyperparameter $rege$, we proceed to transport the points from $S$ to $T$ using the coupling matrix, as shown in the equation: $S_a = \\gamma T$.\n",
    "\n",
    "**5. *1-NN* Classifier on the transported points:**\n",
    "\n",
    "For this final step, we train a *1-NN* classifier using the transported points $S_a$ as features and the labels from `y_webcam`. We then make predictions on the target dataset $T$, and finally, we calculate the accuracy by comparing the actual target labels `y_webcam` with the predicted labels `y_dslr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Entropic_Regularized_OT(S, T, y_train, y_val, rege):\n",
    "    \"\"\"\n",
    "    Perform entropic regularized optimal transport to align S to T and classify with 1-NN.\n",
    "\n",
    "    Parameters:\n",
    "    - S: Source domain data matrix\n",
    "    - T: Target domain data matrix\n",
    "    - y_train: Labels for source data (S)\n",
    "    - y_val: Labels for validation set (for accuracy calculation)\n",
    "    - rege: Entropic regularization parameter for Sinkhorn algorithm\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: Classification accuracy on validation set\n",
    "    \"\"\"\n",
    "    \n",
    "    # Uniform vectors for source and target\n",
    "    ns = S.shape[0]\n",
    "    nt = T.shape[0]\n",
    "    a = np.ones(ns) / ns\n",
    "    b = np.ones(nt) / nt\n",
    "\n",
    "    # Normalized cost matrix\n",
    "    M = cdist(S, T, metric='euclidean')\n",
    "    M_normalized = M / M.max()\n",
    "\n",
    "    # Coupling matrix Î³\n",
    "    gamma = ot.sinkhorn(a, b, M_normalized, rege)\n",
    "\n",
    "    # Transported source points\n",
    "    Sa = np.dot(gamma, T)\n",
    "\n",
    "    # 1-NN classifier on transported source samples to predict labels on T\n",
    "    knn = KNeighborsClassifier(n_neighbors=1)\n",
    "    knn.fit(Sa, y_train)\n",
    "    y_pred = knn.predict(T)\n",
    "    \n",
    "    # Calculate accuracy against true labels for T\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rege: 0.001, Average Accuracy: 0.34256756756756757\n",
      "Rege: 0.01, Average Accuracy: 0.3736486486486486\n",
      "Rege: 0.1, Average Accuracy: 0.4\n",
      "Rege: 1, Average Accuracy: 0.37432432432432433\n",
      "-------------------------------------------\n",
      "Best rege: 0.1, Average accuracy over the source dataset: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Regularization parameter range for tuning\n",
    "rege_values = [0.001, 0.01, 0.1, 1]\n",
    "average_accuracies = []\n",
    "n_trials = 20 \n",
    "\n",
    "# 2-Fold cross-validation with 20 trials on the source dataset\n",
    "for rege in rege_values:\n",
    "    trial_accuracies = []\n",
    "    \n",
    "    for _ in range(n_trials):\n",
    "        # Randomly sample a subset of the source data for training\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_webcam, y_webcam, test_size=0.5)          \n",
    "        \n",
    "        # Train the KNN classifier on the transported source domain\n",
    "        knn = KNeighborsClassifier(n_neighbors=1)\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the target dataset and calculate accuracy\n",
    "        y_pred = knn.predict(X_test)\n",
    "        trial_accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        trial_accuracies.append(trial_accuracy)\n",
    "    \n",
    "    # Average accuracy over all trials for the current `rege`\n",
    "    avg_accuracy = np.mean(trial_accuracies)\n",
    "    average_accuracies.append(avg_accuracy)\n",
    "    print(f'Rege: {rege}, Average Accuracy: {avg_accuracy}')\n",
    "\n",
    "# Select the best `rege` parameter\n",
    "best_rege_index = np.argmax(average_accuracies)\n",
    "best_rege = rege_values[best_rege_index]\n",
    "best_accuracy = average_accuracies[best_rege_index]\n",
    "print('-------------------------------------------')\n",
    "print(f'Best rege: {best_rege}, Average accuracy over the source dataset: {best_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***1-NN* Classifier on the transported points:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on target dataset using best rege: 0.802547770700637\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation with the best `rege`\n",
    "final_accuracy = Entropic_Regularized_OT(X_webcam, X_dslr, y_webcam, y_dslr, best_rege)\n",
    "print(f'Final accuracy on target dataset using best rege: {final_accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
